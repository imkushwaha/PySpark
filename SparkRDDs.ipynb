{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Spark\n",
    "- Streaming Data\n",
    "- Machine Learning\n",
    "- Batch Data\n",
    "- ETL Pipelines\n",
    "- Full load and Replication on going\n",
    "\n",
    "### Why Spark?\n",
    "- Speed\n",
    "- Distributed\n",
    "- Advance Analytics\n",
    "- Real Time\n",
    "- Powerful Caching\n",
    "- Fault Tolerant\n",
    "- Deployment\n",
    "\n",
    "### Spark Architecture\n",
    "\n",
    "\n",
    "### Spark Ecosystem\n",
    "- Spark SQL\n",
    "- Spark Streaming\n",
    "- Spark MLlib\n",
    "- Spark GRAPHX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark RDDs\n",
    "- RDD is the spark's core abstraction which stand for Resilient Distributed Dataset.\n",
    "- RDD is the immutable distributed collection of objects.\n",
    "- internally spark distributes the data in RDD, to different nodes across the cluster to achieve parallelization.\n",
    "\n",
    "### Transformations and Actions\n",
    "\n",
    "Two types of Apache Spark RDD operations are- Transformations and Actions. A Transformation is a function that produces new RDD from the existing RDDs but when we want to work with the actual dataset, at that point Action is performed. When the action is triggered after the result, new RDD is not formed like transformation. \n",
    "\n",
    "- Transformations create a new RDD from an existing one.\n",
    "- Actions return a value to the driver program after running a computation on the RDD.\n",
    "- All transformations in spark are lazy.\n",
    "- Spark only triggers the data flow when there's a action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Spark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Read File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://082b7cf8aa47:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Read File</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Read File>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDDs Functions\n",
    "\n",
    "#### map()\n",
    "- Map is used as a maper of data from one state to other.\n",
    "- It will create a new RDD.\n",
    "- rdd.map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.map(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2', '3', '4', '5'],\n",
       " ['3', '4', '5', '66', '77'],\n",
       " ['12', '43', '6', '7', '8'],\n",
       " ['12', '12', '33']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2', '3', '4', '5'],\n",
       " ['3', '4', '5', '66', '77'],\n",
       " ['12', '43', '6', '7', '8'],\n",
       " ['12', '12', '33']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple function\n",
    "def foo(x):\n",
    "    return x.split(' ')\n",
    "\n",
    "rdd3 = rdd.map(foo)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function\n",
    "def foo(x):\n",
    "    l = x.split(' ')\n",
    "    l2 = []\n",
    "    for s in l:\n",
    "        l2.append(int(s)+2)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 5, 6, 7], [5, 6, 7, 68, 79], [14, 45, 8, 9, 10], [14, 14, 35]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = rdd.map(foo)\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flatMap()\n",
    "- Flat Map is used as a maper of data and explodes data before final output.\n",
    "- It will create a new RDD.\n",
    "- rdd.flatMap(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RDD Data\n",
    "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']\n",
    "\n",
    "###### Mapped Data\n",
    "[['1', '2', '3', '4', '5'],\n",
    " ['3', '4', '5', '66', '77'],\n",
    " ['12', '43', '6', '7', '8'],\n",
    " ['12', '12', '33']]\n",
    "\n",
    " ###### Flatmapped Data\n",
    " ['1', '2', '3', '4', '5', '3', '4', '5', '66', '77', '12', '43', '6', '7', '8', '12', '12', '33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2', '3', '4', '5'],\n",
       " ['3', '4', '5', '66', '77'],\n",
       " ['12', '43', '6', '7', '8'],\n",
       " ['12', '12', '33']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappedRdd = rdd.map(lambda x: x.split(\" \"))\n",
    "mappedRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '66',\n",
       " '77',\n",
       " '12',\n",
       " '43',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '12',\n",
       " '12',\n",
       " '33']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatmappedRdd = rdd.flatMap(lambda x: x.split(\" \"))\n",
    "flatmappedRdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter()\n",
    "- Filter is used to remove the elements from the RDD\n",
    "- It will create a new RDD\n",
    "- rdd.filter(lambda x:x!= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.filter(lambda x: x != '12 12 33')\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(x):\n",
    "    return 1==1  # True\n",
    "\n",
    "rdd2 = rdd.filter(foo)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def noo(x):\n",
    "    return 1==2  # False\n",
    "\n",
    "rdd2 = rdd.filter(noo)\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(x):\n",
    "    if x == '12 12 33':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "rdd2 = rdd.filter(foo)\n",
    "rdd2.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distinct()\n",
    "- Distinct is used to get the distinct elements in RDD\n",
    "- It will create a new RDD\n",
    "- rdd.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 4 5 66 77', '12 43 6 7 8', '12 12 33', '1 2 3 4 5']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.distinct()\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '66',\n",
       " '77',\n",
       " '12',\n",
       " '43',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '12',\n",
       " '12',\n",
       " '33']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.flatMap(lambda x: x.split(\" \"))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4', '66', '77', '12', '8', '33', '2', '3', '5', '43', '6', '7']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = rdd2.distinct()\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4', '66', '77', '12', '8', '33', '2', '3', '5', '43', '6', '7']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x: x.split(\" \")).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupByKey()\n",
    "- GroupByKey is used to create groups based on keys in RDD\n",
    "- For groupByKey to work properly the data must be in the format of (k,v), (k,v), (k2,v), (k2,v2)\n",
    "   - Example: (\"Apple\",1), (\"Ball\",1), (\"Apple\",1)\n",
    "- It will create a new RDD\n",
    "- rdd.groupByKey()\n",
    "- mapValues(list) are usually used to get the group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this mango company animal',\n",
       " 'cat dog ant mic laptop',\n",
       " 'chair switch mobile am charger cover',\n",
       " 'amanda any alarm ant']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile(\"sample_words.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'mango',\n",
       " 'company',\n",
       " 'animal',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'ant',\n",
       " 'mic',\n",
       " 'laptop',\n",
       " 'chair',\n",
       " 'switch',\n",
       " 'mobile',\n",
       " 'am',\n",
       " 'charger',\n",
       " 'cover',\n",
       " 'amanda',\n",
       " 'any',\n",
       " 'alarm',\n",
       " 'ant']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.flatMap(lambda x: x.split(' '))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 4),\n",
       " ('mango', 5),\n",
       " ('company', 7),\n",
       " ('animal', 6),\n",
       " ('cat', 3),\n",
       " ('dog', 3),\n",
       " ('ant', 3),\n",
       " ('mic', 3),\n",
       " ('laptop', 6),\n",
       " ('chair', 5),\n",
       " ('switch', 6),\n",
       " ('mobile', 6),\n",
       " ('am', 2),\n",
       " ('charger', 7),\n",
       " ('cover', 5),\n",
       " ('amanda', 6),\n",
       " ('any', 3),\n",
       " ('alarm', 5),\n",
       " ('ant', 3)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = rdd2.map(lambda x: (x,len(x)))\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', <pyspark.resultiterable.ResultIterable at 0x7f1f91ce00a0>),\n",
       " ('mango', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89040>),\n",
       " ('cat', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89220>),\n",
       " ('ant', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89a60>),\n",
       " ('laptop', <pyspark.resultiterable.ResultIterable at 0x7f1f91c895b0>),\n",
       " ('chair', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89820>),\n",
       " ('switch', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89130>),\n",
       " ('mobile', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89850>),\n",
       " ('am', <pyspark.resultiterable.ResultIterable at 0x7f1f91c892b0>),\n",
       " ('company', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89e80>),\n",
       " ('animal', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89ee0>),\n",
       " ('dog', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89e50>),\n",
       " ('mic', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89fd0>),\n",
       " ('charger', <pyspark.resultiterable.ResultIterable at 0x7f1f91c89f70>),\n",
       " ('cover', <pyspark.resultiterable.ResultIterable at 0x7f1f91c43070>),\n",
       " ('amanda', <pyspark.resultiterable.ResultIterable at 0x7f1f91c430d0>),\n",
       " ('any', <pyspark.resultiterable.ResultIterable at 0x7f1f91c43130>),\n",
       " ('alarm', <pyspark.resultiterable.ResultIterable at 0x7f1f91c43190>)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', [4]),\n",
       " ('mango', [5]),\n",
       " ('cat', [3]),\n",
       " ('ant', [3, 3]),\n",
       " ('laptop', [6]),\n",
       " ('chair', [5]),\n",
       " ('switch', [6]),\n",
       " ('mobile', [6]),\n",
       " ('am', [2]),\n",
       " ('company', [7]),\n",
       " ('animal', [6]),\n",
       " ('dog', [3]),\n",
       " ('mic', [3]),\n",
       " ('charger', [7]),\n",
       " ('cover', [5]),\n",
       " ('amanda', [6]),\n",
       " ('any', [3]),\n",
       " ('alarm', [5])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.groupByKey().mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduceByKey()\n",
    "- ReduceByKey is used to combined data based on keys in RDD\n",
    "- For reduceByKey to work properly the data must be in the format of (k,v), (k,v), (k2,v), (k2,v2)\n",
    "     - Example: (\"Apple\",1), (\"Ball\",1), (\"Apple\",1)\n",
    "- It will create a new RDD\n",
    "- rdd.reduceByKey(lambdax, y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
